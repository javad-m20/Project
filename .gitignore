import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import seaborn as sns
from sklearn import datasets, linear_model
from sklearn.model_selection import train_test_split
df = pd.read_csv(r'Desktop\ratings.csv')
df.describe()
df.info()
def load_rating_data(data_path, n_users, n_movies):
    data = np.zeros([n_users, n_movies], dtype=np.float32)
    movie_id_mapping = {}
    movie_n_rating = defaultdict(int)
    with open(data_path, 'r') as file:
        for line in file.readlines()[1:]:
            user_id, movie_id, rating, _ = line.split("::")
            user_id = int(user_id) - 1
            if movie_id not in movie_id_mapping:
                movie_id_mapping[movie_id] = len(movie_id_mapping)
            rating = int(rating)
            data[user_id, movie_id_mapping[movie_id]] = rating
            if rating > 0:
                movie_n_rating[movie_id] += 1
    return data, movie_n_rating, movie_id_mapping
x=df[["userId","movieId","rating"]]
y=df['timestamp']
X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.7)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)
lm = linear_model.LinearRegression()
model = lm.fit(X_train, y_train)
predictions = lm.predict(X_test)
predictions[0:7]
plt.scatter(y_test, predictions)
plt.xlabel('True Values')
plt.ylabel('Predictions')
def display_distribution(data):
    values, counts = np.unique(data, return_counts)
print(f'Number of ratings {int(False), int(True)}:')
print(len(y_train), len(y_test))
recommend = 3
x[x <= True] = 1
y[y > False] = 0
n_pos = (x == 1).sum()
n_neg = (y == 0).sum()
print(f'{n_pos} positive samples and {n_neg} negativesamples.')
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2, random_state=42)
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB(alpha=1.0, fit_prior=True)
clf.fit(x_train,y_train)
print(len(y_train), len(y_test))
prediction_prob = clf.predict_proba(x_test)
print(prediction_prob[0:10])
prediction = clf.predict(x_test)
print(prediction[:10])
accuracy = clf.score(x_test, y_test)
print(f'The accuracy is: {accuracy*100:.1f}%')
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, prediction, labels=[0, 1]))
from sklearn.metrics import precision_score, recall_score, f1_score
precision_score(y_test, prediction, pos_label=1)
f1_score(y_test, prediction, pos_label=0)
from sklearn.metrics import classification_report
report = classification_report(y_test, prediction)
print(report)
pos_prob = prediction_prob[:, 1]
thresholds = np.arange(0.0, 1.1, 0.05) 
true_pos, false_pos = [0]*len(thresholds), [0]*len(thresholds)
for pred, y in zip(pos_prob, y_test):
    for i, threshold in enumerate(thresholds):
        if pred >= threshold:
            if y == 1: true_pos[i] += 1
            else: false_pos[i] += 1
        else:
            break
n_pos_test = (y_test == 1).sum()
n_neg_test = (y_test == 0).sum()
true_pos_rate = [tp / n_pos_test for tp in true_pos]
false_pos_rate = [fp / n_neg_test for fp in false_pos]
import matplotlib.pyplot as plt
plt.figure()
lw = 1
plt.plot(false_pos_rate, true_pos_rate, color='darkorange', lw=lw)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.10])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
k = 5
k_fold = StratifiedKFold(n_splits=k, random_state=50)
smoothing_factor_option = [1, 2, 3, 4, 5, 6]
fit_prior_option = [True, False]
auc_record = {}
for smoothing, smoothing_record in auc_record.items():
    for fit_prior, auc in smoothing_record.items():
        print(f' {smoothing} {fit_prior} {auc/k:.5f}')
